{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style='font-size:1.5em'>**üíª W07 Lab Notebook**</font><br>\n",
    "<font style='font-size:1.3em;color:#888888'>Normalising JSON + the Groupby -> Apply -> Combine Strategy </font>\n",
    "\n",
    "<font style='font-size:1.2em'>LSE [DS105A](https://lse-dsi.github.io/DS105/autumn-term/index.html){style=\"color:#e26a4f;font-weight:bold\"} ‚Äì Data for Data Science (2024/25) </font>\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"color: #333333; background-color:rgba(226, 106, 79, 0.075); border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); padding: 20px 0 20px 10px; margin: 10px 0 10px 0; flex: 1 1 calc(45% - 20px);min-width: 250px;max-width: 350px;align-items:top;min-height: calc(45% - 20px); box-sizing: border-box;font-size:0.9em;\">\n",
    "\n",
    "üóìÔ∏è **DATE:** 15 November 2024 \n",
    "</div>\n",
    "\n",
    "\n",
    "**CREATORS:**  \n",
    "\n",
    "- [Alex Soldatkin](https://github.com/alex-soldatkin) provided the dataset, the use case and a starting code\n",
    "- Dr. [Jon Cardoso-Silva](https://jonjoncardoso.github.io) adjusted the content to meet the lecture more closely\n",
    "\n",
    "**DEPARTMENT:** [LSE Data Science Institute](https://lse.ac.uk/dsi)\n",
    "\n",
    "**OBJECTIVE**: Practice normalising JSON data and using the groupby -> apply -> combine strategy to aggregate data.\n",
    "\n",
    "**REFERENCES:**\n",
    "\n",
    "- The [`pd.json_normalize()` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) to convert JSON data more easily into tabular format\n",
    "\n",
    "- The [DataFrame.explode()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.explode.html) function to handle cases when columns are made out of lists\n",
    "\n",
    "In the labs later (second notebook), we will also cover:\n",
    "\n",
    "- The [DataFrame.groupby()](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html) function, combined with apply() and agg() to aggregate data \n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:white;padding:0.5em;margin-left:2em;margin-bottom:1em;border-radius:0.5em;font-family: monospace;border: 1px solid #eda291;font-size:1.05em;width:500px\">\n",
    "\n",
    "üíΩ **DATA SPECIFICATION CARD:**\n",
    "\n",
    "<font style=\"font-size:0.8em\">We're going to use data from the [OpenSanctions](https://www.opensanctions.org/) project. This dataset includes information about individuals and entities that governments and international organizations have sanctioned worldwide. OpenSanctions is operated by a German company, [OpenSanctions Datenbanken GmbH](https://www.opensanctions.org/docs/about/), and has received funding from the German Federal Ministry for Education and Research. They offer a paid API for accessing the data, but you can also download the [data in bulk](https://www.opensanctions.org/datasets/sanctions/) for free, for academic and research purposes.</font>\n",
    "\n",
    "A few things to know about the dataset:\n",
    "\n",
    "- **We are focusing on Targets.** These are the individuals and entities that have been sanctioned. This dataset includes information about the name, country, and other 'properties' of the targets.\n",
    "\n",
    "- **We have filtered for Russian Targets.** This in part because Alex, who provided us with the data sample for this lab, is doing a PhD where he focuses on studying Russia, and also because the dataset is large and we want to make it more manageable for this lab.\n",
    "\n",
    "- **We are using a small random sample.** Again, this is to make the dataset more manageable for this lab. The full dataset is much larger. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert files to a suitable Python format (list or dictionary)\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Let's normalise the JSON data\n",
    "\n",
    "- You can work alone or in small groups for this. \n",
    "\n",
    "- If you want, feel free to play a game of <span style=\"display: inline-block; padding: 0 7.5px; font-size: 12px; font-weight: bold; line-height: 18px; white-space: nowrap; border: 1px solid rgba(20, 18, 11, 0.75); border-radius: 0.5em; color: rgb(20, 18, 11); background-color: rgba(255, 255, 255, 0.75); vertical-align: top; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1)\"> üßë‚Äç‚úàÔ∏è Pilot</span> and <span style=\"display: inline-block; padding: 0 7.5px; font-size: 12px; font-weight: bold; line-height: 18px; white-space: nowrap; border: 1px solid rgba(20, 18, 11, 0.75); border-radius: 0.5em; color: #ac831d; background-color: rgba(255, 255, 255, 0.75); vertical-align: top; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1)\">üôã Copilot (s)</span> like we've done in the past.\n",
    "\n",
    "Treat everything that comes below as üéØ **ACTION POINTS:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read JSON data into a Python object\n",
    "\n",
    "We have a JSON file called `data/sample_single_target.json` that contains information about a single target of sanctions.\n",
    "\n",
    "Run the code below that reads the data from the file into a suitable Python object (either list or dictionary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/opensanctions/sample_single_target.json', mode='r') as file:\n",
    "    sample_target = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Explore the JSON data:\n",
    "\n",
    "Either browse the file or print the object you read the JSON data into to understand its structure.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What is the type of the object that you read the JSON data into?\n",
    "\n",
    "    My answer: \n",
    "\n",
    "    > Edit this markdown and write your answer here.\n",
    "\n",
    "2. Is this a flat or nested JSON object?\n",
    "\n",
    "    My answer: \n",
    "\n",
    "    > Edit this markdown and write your answer here.\n",
    "\n",
    "3. Can this object be converted into a DataFrame directly (with `pd.DataFrame()`), or do we need to do some pre-processing first?\n",
    "\n",
    "    My answer: \n",
    "\n",
    "    > Edit this markdown and write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Normalise the JSON data\n",
    "\n",
    "- Convert the JSON data into a DataFrame using the `pd.json_normalize()` function.\n",
    "\n",
    "- Store the resulting DataFrame in a variable called `df_sample`.\n",
    "\n",
    "You should see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the cell below to see what your DataFrame should look like\n",
    "# Image(\"../figures/opensanctions/df_sample_v1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Subset for the most interesting `properties` columns\n",
    "\n",
    "We want to focus on the following properties:\n",
    "\n",
    "| Property                  | Description                                                                                     | Type   |\n",
    "|---------------------------|-------------------------------------------------------------------------------------------------|--------|\n",
    "| `properties.alias`        | The different names that the target is known by.                                                | List   |\n",
    "| `properties.nationality`  | The nationality(ies) of the target.                                                             | List   |\n",
    "| `properties.birthCountry` | The country where the target was born. This is stored as a list but should have only one element.| List   |\n",
    "| `properties.sourceUrl`    | The URL where the information about the target was sourced from. This is stored as a list but should have only one element. | List   |\n",
    "| `properties.sanctions`    | The sanctions that the target is subject to.                                                    | List   |\n",
    "\n",
    "\n",
    "- Save the names of the columns above to a list called `interesting_columns`.\n",
    "\n",
    "- Subset the DataFrame to keep only the columns listed above.\n",
    "\n",
    "- Replace the `df_sample` variable with the new DataFrame that contains only the interesting columns.\n",
    "\n",
    "üí° **TIP:** If you have GitHub Copilot installed on your machine, try adding the instructions above to the AI and see if it produces the output you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the cell below to see what your DataFrame should look like\n",
    "# Image(\"../figures/opensanctions/df_sample_v2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_properties = ['properties.alias', 'properties.nationality', 'properties.birthCountry', 'properties.sourceUrl', 'properties.sanctions']\n",
    "\n",
    "# properties.sanctions is a column made of dictionaries, so we need to explode it\n",
    "df_sample = pd.json_normalize(sample_target)[interesting_properties]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Rename the columns\n",
    "\n",
    "Let's get rid of the `properties.` prefix in the column names.\n",
    "\n",
    "If you created the `interesting_columns` list and the `df_sample` correctly, you can run the code below to rename the columns. \n",
    "\n",
    "Cut this piece of code and paste it in the cell below:\n",
    "\n",
    "```python\n",
    "new_column_names = [col.split('.')[1] for col in interesting_properties]\n",
    "\n",
    "# Here's a new way to rename columns\n",
    "df_sample.columns = new_column_names\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ 1.6 String Manipulation (Don't explode anything just yet)\n",
    "\n",
    "We are interested in understanding which countries/entities have imposed sanctions on the target. This means the only column we want to explode is the `properties.sanctions` column. \n",
    "\n",
    "All the other columns, despite being lists, should not be exploded. It makes a lot more sense to just convert them to meaningful strings.\n",
    "\n",
    "We can use the `apply()` function on each of these columns to convert the lists into strings.\n",
    "\n",
    "Here's, for example, how I would convert the `birth_country` column from a list to a string:\n",
    "\n",
    "```python\n",
    "# Because I know the `birthCountry` column is a list that has just a single element, \n",
    "# I can extract it directly like this.\n",
    "# Run it and check the result before assigning it back to the column\n",
    "df_sample['birthCountry'].apply(lambda x: x[0])\n",
    "\n",
    "# To make this change permanent, assign it back to the column\n",
    "df_sample['birthCountry'] = df_sample['birthCountry'].apply(lambda x: x[0])\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'birthCountry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'birthCountry'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Convert the birthCountry column to a single string\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbirthCountry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbirthCountry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'birthCountry'"
     ]
    }
   ],
   "source": [
    "# TODO: Convert the birthCountry column to a single string\n",
    "df_sample['birthCountry'] = df_sample['birthCountry'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Similarly, grab just the first name from the alias list\n",
    "df_sample['alias'] = df_sample['alias'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Similarly, grab just the first URL from the sourceUrl list\n",
    "df_sample['sourceUrl'] = df_sample['sourceUrl'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Use the \", \".join() function to convert the list of nationalities to a single string that separates all the nationalities with a comma and a space\n",
    "df_sample['nationality'] = df_sample['nationality'].apply(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the cell below to see what your DataFrame should look like\n",
    "# Image(\"../figures/opensanctions/df_sample_v3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Explode the columns\n",
    "\n",
    "- Use the [DataFrame.explode()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.explode.html) function to explode the `sanctions` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the cell below to see what your DataFrame should look like\n",
    "# Image(\"../figures/opensanctions/df_sample_v4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.explode('sanctions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8. See the solution\n",
    "\n",
    "Putting it all together, here's what the solution would look like if you were to use method-chaining:\n",
    "\n",
    "<details><summary>Click HERE for the solution</summary>\n",
    "\n",
    "```python\n",
    "interesting_columns = ['properties.alias', \n",
    "                       'properties.nationality', \n",
    "                       'properties.birthCountry', \n",
    "                       'properties.sourceUrl', \n",
    "                       'properties.sanctions']\n",
    "\n",
    "with open('../data/opensanctions/sample_single_target.json', mode='r') as file:\n",
    "    sample_target = json.load(file)\n",
    "\n",
    "df_sample = (\n",
    "    pd.json_normalize(sample_target)\n",
    "    [interesting_columns]\n",
    "    .rename(columns={\n",
    "        'properties.alias': 'alias',\n",
    "        'properties.nationality': 'nationality',\n",
    "        'properties.birthCountry': 'birthCountry',\n",
    "        'properties.sourceUrl': 'sourceUrl',\n",
    "        'properties.sanctions': 'sanctions'\n",
    "    })\n",
    "    .assign(\n",
    "        alias=lambda x: x['alias'].apply(lambda x: x[0]),\n",
    "        sourceUrl=lambda x: x['sourceUrl'].apply(lambda x: x[0]),\n",
    "        nationality=lambda x: x['nationality'].apply(lambda x: \", \".join(x)),\n",
    "        birthCountry=lambda x: x['birthCountry'].apply(lambda x: x[0])\n",
    "    )\n",
    "    .explode('sanctions')\n",
    ")\n",
    "\n",
    "df_sample\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Unnest the `sanctions` column\n",
    "\n",
    "We have a lot of stuff but our `sanctions` column is still nested.\n",
    "\n",
    "We can't explode it, as the data inside is not a list, but a dictionary.\n",
    "\n",
    "Give it a go:\n",
    "\n",
    "```python\n",
    "# This won't work. Explode only works with lists\n",
    "df_sample.explode('sanctions')\n",
    "```\n",
    "\n",
    "We need to:\n",
    "\n",
    "- Keep the other columns as they are\n",
    "- Work separately on the `sanctions` column, using the `pd.json_normalize()` function to normalise the data inside it.\n",
    "- Concatenate the resulting DataFrame with the original one, keeping the index aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Convert the entire `sanctions` column into a DataFrame of its own\n",
    "\n",
    "For this to work, we first need to convert the 'sanctions' column back to a 'pure Python' list of dictionaries\n",
    "\n",
    "```python\n",
    "# You can normalise a pandas column when they are lists of dictionaries\n",
    "# json_normalise is not just for 'pure Python' lists of dictionaries\n",
    "pd.json_normalize(df_sample['sanctions'])\n",
    "```\n",
    "\n",
    "Copy the code above and paste it in the cell below to observe the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the resulting DataFrame above, we definitely want the `properties.country` (renamed to just `sanction_country`), but we want it as a string, not as a list.\n",
    "\n",
    "Figure out how to create this column and add it to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write some code until I can add a df_sample['sanction_country'] column to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the cell below to see what your DataFrame should look like\n",
    "# Image(\"../figures/opensanctions/df_sample_v5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. A larger dataset\n",
    "\n",
    "Let's use a much larger dataset now. Small tweaks to the code are necessary, as some of the data is missing plus we have more than one target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of JSON objects (each element is a JSON object like the sample we've used above)\n",
    "df_targets = pd.read_json('../data/opensanctions/targets_sample_4000.jsonl', lines=True)\n",
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, we just care about the 'properties' columns, but this time we have a lot more data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets['properties'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can normalise the 'properties' column and work with the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_columns = ['alias', 'nationality', 'birthCountry', 'sourceUrl', 'sanctions']\n",
    "pd.json_normalize(df_targets['properties'])[interesting_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Notice how this time around there are some NaN values in the DataFrame. This is because some of the 'properties' columns are missing in some of the rows.\n",
    "\n",
    "We need to consider this when we normalise the data!\n",
    "\n",
    "Your task now is to **understand everything the code below does** and then **run it**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>nationality</th>\n",
       "      <th>birthCountry</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>sanction_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Limited Liability Company \"Composite Tech‚Ññlogy\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–î–æ–≤—Ç–∞—î–≤ –ê–ª—ñ—Ö–∞–Ω –Ü—Å–∞–π–æ–≤–∏—á</td>\n",
       "      <td>ru</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–î–æ–≤—Ç–∞—î–≤ –ê–ª—ñ—Ö–∞–Ω –Ü—Å–∞–π–æ–≤–∏—á</td>\n",
       "      <td>ru</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–°–∞–º–∞—Ä—á–µ–Ω–∫–æ –°–≤–µ—Ç–ª–∞–Ω–∞ –í–∏—Ç–∞–ª—å–µ–≤–Ω–∞</td>\n",
       "      <td>ua</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Ginsburg Vladimir</td>\n",
       "      <td>ru</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://sanctionssearch.ofac.treas.gov/Details...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>BABII ANNA</td>\n",
       "      <td>ua</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>BABII ANNA</td>\n",
       "      <td>ua</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>BABII ANNA</td>\n",
       "      <td>ua</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10103 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                alias nationality  \\\n",
       "0     Limited Liability Company \"Composite Tech‚Ññlogy\"        None   \n",
       "1                             –î–æ–≤—Ç–∞—î–≤ –ê–ª—ñ—Ö–∞–Ω –Ü—Å–∞–π–æ–≤–∏—á          ru   \n",
       "1                             –î–æ–≤—Ç–∞—î–≤ –ê–ª—ñ—Ö–∞–Ω –Ü—Å–∞–π–æ–≤–∏—á          ru   \n",
       "2                                                None        None   \n",
       "3                      –°–∞–º–∞—Ä—á–µ–Ω–∫–æ –°–≤–µ—Ç–ª–∞–Ω–∞ –í–∏—Ç–∞–ª—å–µ–≤–Ω–∞          ua   \n",
       "...                                               ...         ...   \n",
       "3997                                Ginsburg Vladimir          ru   \n",
       "3998                                             None        None   \n",
       "3999                                       BABII ANNA          ua   \n",
       "3999                                       BABII ANNA          ua   \n",
       "3999                                       BABII ANNA          ua   \n",
       "\n",
       "     birthCountry                                          sourceUrl  \\\n",
       "0            None                                               None   \n",
       "1            None                                               None   \n",
       "1            None                                               None   \n",
       "2            None                                               None   \n",
       "3            None                                               None   \n",
       "...           ...                                                ...   \n",
       "3997         None                                               None   \n",
       "3998         None  https://sanctionssearch.ofac.treas.gov/Details...   \n",
       "3999         None                                               None   \n",
       "3999         None                                               None   \n",
       "3999         None                                               None   \n",
       "\n",
       "     sanction_country  \n",
       "0                  ua  \n",
       "1                  ua  \n",
       "1                  ua  \n",
       "2                None  \n",
       "3                  ua  \n",
       "...               ...  \n",
       "3997               ua  \n",
       "3998               us  \n",
       "3999               ua  \n",
       "3999               ua  \n",
       "3999               ua  \n",
       "\n",
       "[10103 rows x 5 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will read this first, outside the method chain, so it's easier to see what's happening\n",
    "df_targets = pd.read_json('../data/opensanctions/targets_sample_4000.jsonl', lines=True)\n",
    "\n",
    "# I will also leave this outside the method chain, so it's easier to see what's happening\n",
    "interesting_columns = ['alias', 'nationality', 'birthCountry', 'sourceUrl', 'sanctions']\n",
    "df_targets = pd.json_normalize(df_targets['properties'])[interesting_columns]\n",
    "\n",
    "# Have you seen the assign() method before? It's a very useful method to add new columns to a DataFrame\n",
    "# Do you see what we're doing differently here?\n",
    "df_targets = (\n",
    "    df_targets\n",
    "    .assign(\n",
    "        alias=lambda x: x['alias'].apply(lambda x: x[0] if isinstance(x, list) else None),\n",
    "        sourceUrl=lambda x: x['sourceUrl'].apply(lambda x: x[0] if isinstance(x, list) else None),\n",
    "        nationality=lambda x: x['nationality'].apply(lambda x: \", \".join(x) if isinstance(x, list) else None),\n",
    "        birthCountry=lambda x: x['birthCountry'].apply(lambda x: x[0] if isinstance(x, list) else None)\n",
    "    )\n",
    "    .explode('sanctions')\n",
    ")\n",
    "\n",
    "# Here's another way to add the 'sanction_country' column\n",
    "sanction_country = pd.json_normalize(df_targets['sanctions'])['properties.country']\n",
    "sanction_country = sanction_country.apply(lambda x: x[0] if isinstance(x, list) else None).tolist()\n",
    "df_targets['sanction_country'] = sanction_country\n",
    "\n",
    "df_targets = df_targets.drop(columns='sanctions')\n",
    "\n",
    "df_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Groupby -> Apply -> Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to group the data by the `sanction_country` column and count the number of sanctions imposed by each country.\n",
    "\n",
    "(If you have time, create a bar plot to visualise the results)\n",
    "\n",
    "(If you REALLY have time, search online for the `pycountry` library and use it to convert the country codes to meaningful country names -- use pd.merge() to join the dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
